{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea7f4c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd4118b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = './data/train.csv'\n",
    "n_folds = 4\n",
    "min_train_frac = 0.5\n",
    "\n",
    "lag_list      = (1,2,5,10,20,60,120,240,360,480)\n",
    "roll_windows  = (5,20,60,120,240,360)\n",
    "z_windows     = (60,120)          \n",
    "ewma_spans    = (16,32)           \n",
    "rcorr_windows = (20,60,120)\n",
    "rcov_windows  = (20,60,120)\n",
    "rcorr_topk    = 6                 \n",
    "\n",
    "# PCA usage\n",
    "use_pca_y1 = False               \n",
    "use_pca_y2 = False                 \n",
    "pca_components_y2 = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9241832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pick_top_variance_features(df, base_cols, k=6):\n",
    "    variances = df[base_cols].var().sort_values(ascending=False)\n",
    "    return variances.index[:min(k, len(variances))].tolist()\n",
    "\n",
    "def make_features_full(df,\n",
    "                       lag_list=(1,2,5,10,20,60,120,240,360,480),\n",
    "                       roll_windows=(5,20,60,120,240,360),\n",
    "                       z_windows=(60,120),\n",
    "                       ewma_spans=(16,32),\n",
    "                       rcorr_windows=(20,60,120),\n",
    "                       rcov_windows=(20,60,120),\n",
    "                       rcorr_topk=6):\n",
    "    df = df.copy()\n",
    "    base_cols = [c for c in df.columns if c not in ['time','Y1','Y2']]\n",
    "\n",
    "    # Lags\n",
    "    for lag in lag_list:\n",
    "        for c in base_cols:\n",
    "            df[f\"{c}_lag{lag}\"] = df[c].shift(lag)\n",
    "\n",
    "    # First differences & simple returns (shifted)\n",
    "    for c in base_cols:\n",
    "        df[f\"{c}_diff1\"] = df[c].diff().shift(1)\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            df[f\"{c}_ret1\"] = ((df[c] / df[c].shift(1)) - 1.0).shift(1)\n",
    "\n",
    "    # Rolling mean/std on raw and on diffs (shifted)\n",
    "    for w in roll_windows:\n",
    "        for c in base_cols:\n",
    "            s = df[c].shift(1)\n",
    "            df[f\"{c}_rollmean{w}\"] = s.rolling(w).mean()\n",
    "            df[f\"{c}_rollstd{w}\"]  = s.rolling(w).std()\n",
    "            d = df[f\"{c}_diff1\"]\n",
    "            df[f\"{c}_diff1_rollmean{w}\"] = d.rolling(w).mean()\n",
    "            df[f\"{c}_diff1_rollstd{w}\"]  = d.rolling(w).std()\n",
    "\n",
    "    # Rolling z-scores (shifted)\n",
    "    for w in z_windows:\n",
    "        for c in base_cols:\n",
    "            s = df[c].shift(1)\n",
    "            mu = s.rolling(w).mean()\n",
    "            sd = s.rolling(w).std()\n",
    "            df[f\"{c}_z{w}\"] = (s - mu) / sd\n",
    "\n",
    "    # EWMA means (shifted)\n",
    "    for span in ewma_spans:\n",
    "        for c in base_cols:\n",
    "            s = df[c].shift(1)\n",
    "            df[f\"{c}_ewma{span}\"] = s.ewm(span=span, adjust=False).mean()\n",
    "\n",
    "    # Rolling correlations, covariances, and beta among top-variance features (shifted inputs)\n",
    "    topv = _pick_top_variance_features(df, base_cols, k=rcorr_topk)\n",
    "    for w in rcorr_windows:\n",
    "        for i in range(len(topv)):\n",
    "            for j in range(i+1, len(topv)):\n",
    "                a, b = topv[i], topv[j]\n",
    "                s1 = df[a].shift(1); s2 = df[b].shift(1)\n",
    "                df[f\"rcorr_{a}_{b}_w{w}\"] = s1.rolling(w).corr(s2)\n",
    "\n",
    "    for w in rcov_windows:\n",
    "        for i in range(len(topv)):\n",
    "            for j in range(i+1, len(topv)):\n",
    "                a, b = topv[i], topv[j]\n",
    "                s1 = df[a].shift(1); s2 = df[b].shift(1)\n",
    "                cov = s1.rolling(w).cov(s2)\n",
    "                var_b = s2.rolling(w).var()\n",
    "                beta = cov / var_b\n",
    "                df[f\"rcov_{a}_{b}_w{w}\"]  = cov\n",
    "                df[f\"rbeta_{a}_on_{b}_w{w}\"] = beta\n",
    "\n",
    "    # Drop NaNs created by lags/rolls\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "    feature_cols = [c for c in df.columns if c not in ['Y1','Y2']]\n",
    "    X_all = df[feature_cols]\n",
    "    y1_all = df['Y1']\n",
    "    y2_all = df['Y2']\n",
    "    return X_all, y1_all, y2_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e21e5c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_folds_by_time(times, n_folds=4, min_train_frac=0.5):\n",
    "    uniq = np.unique(times)\n",
    "    n = len(uniq)\n",
    "    n_folds = max(2, n_folds)\n",
    "    start_train_idx = int(n * min_train_frac)\n",
    "    remain = n - start_train_idx\n",
    "    seg = max(1, remain // n_folds)\n",
    "    folds = []\n",
    "    for k in range(n_folds):\n",
    "        val_start = start_train_idx + k * seg\n",
    "        val_end   = start_train_idx + (k + 1) * seg if k < n_folds - 1 else n\n",
    "        if val_start >= val_end or val_start >= n:\n",
    "            continue\n",
    "        train_time_max = uniq[val_start - 1]\n",
    "        val_time_start = uniq[val_start]\n",
    "        val_time_end   = uniq[val_end - 1]\n",
    "        train_idx = np.where(times <= train_time_max)[0]\n",
    "        val_mask  = (times >= val_time_start) & (times <= val_time_end)\n",
    "        val_idx   = np.where(val_mask)[0]\n",
    "        if len(train_idx) and len(val_idx):\n",
    "            folds.append((train_idx, val_idx))\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a623568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_y1():\n",
    "    models = []\n",
    "    if XGBRegressor is not None:\n",
    "        models.append(('XGBoost', XGBRegressor(\n",
    "            objective='reg:squarederror',\n",
    "            learning_rate=0.02,\n",
    "            n_estimators=3500,\n",
    "            max_depth=5,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.9,\n",
    "            reg_lambda=3.0,\n",
    "            tree_method='hist',\n",
    "            random_state=42,\n",
    "            verbosity=0\n",
    "        )))\n",
    "    if CatBoostRegressor is not None:\n",
    "        models.append(('CatBoost', CatBoostRegressor(\n",
    "            loss_function='RMSE',\n",
    "            learning_rate=0.03,\n",
    "            depth=6,\n",
    "            l2_leaf_reg=8.0,\n",
    "            iterations=3000,\n",
    "            random_seed=42,\n",
    "            verbose=False\n",
    "        )))\n",
    "    return models\n",
    "\n",
    "def models_y2():\n",
    "    models = []\n",
    "    if XGBRegressor is not None:\n",
    "        models.append(('XGBoost', XGBRegressor(\n",
    "            objective='reg:squarederror',\n",
    "            learning_rate=0.018,\n",
    "            n_estimators=4800,\n",
    "            max_depth=7,\n",
    "            min_child_weight=3,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            gamma=0.2,\n",
    "            reg_lambda=4.0,\n",
    "            tree_method='hist',\n",
    "            random_state=42,\n",
    "            verbosity=0\n",
    "        )))\n",
    "    if CatBoostRegressor is not None:\n",
    "        models.append(('CatBoost', CatBoostRegressor(\n",
    "            loss_function='RMSE',\n",
    "            learning_rate=0.025,\n",
    "            depth=8,\n",
    "            l2_leaf_reg=14.0,\n",
    "            iterations=5000,\n",
    "            rsm=0.85,\n",
    "            random_seed=42,\n",
    "            verbose=False\n",
    "        )))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b08479c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cv(X, y, models, folds, use_pca=False, pca_components=32):\n",
    "    results = {name: [] for name, _ in models}\n",
    "    preds_cache = {name: [] for name, _ in models}  # list of (val_indices, preds) per fold\n",
    "\n",
    "    for fold_id, (tr_idx, va_idx) in enumerate(folds, 1):\n",
    "        X_tr = X.iloc[tr_idx].copy(); X_va = X.iloc[va_idx].copy()\n",
    "        y_tr = y.iloc[tr_idx].copy(); y_va = y.iloc[va_idx].copy()\n",
    "        feat_cols = [c for c in X_tr.columns if c != 'time']\n",
    "        X_tr_f = X_tr[feat_cols].values; X_va_f = X_va[feat_cols].values\n",
    "\n",
    "        if use_pca:\n",
    "            scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "            X_tr_s = scaler.fit_transform(X_tr_f)\n",
    "            X_va_s = scaler.transform(X_va_f)\n",
    "            pca = PCA(n_components=min(pca_components, X_tr_s.shape[1]))\n",
    "            X_tr_use = pca.fit_transform(X_tr_s)\n",
    "            X_va_use = pca.transform(X_va_s)\n",
    "        else:\n",
    "            X_tr_use = X_tr_f\n",
    "            X_va_use = X_va_f\n",
    "\n",
    "        for name, model in models:\n",
    "            model.fit(X_tr_use, y_tr)\n",
    "            y_hat = model.predict(X_va_use)\n",
    "            preds_cache[name].append((va_idx, y_hat))\n",
    "            r2 = r2_score(y_va, y_hat)\n",
    "            results[name].append(r2)\n",
    "\n",
    "        print(f\"[fold {fold_id}/{len(folds)}] done\")\n",
    "\n",
    "    return results, preds_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c0e25bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: (80000, 17)\n",
      "Features shape: (79520, 710)\n",
      "Folds: 4\n"
     ]
    }
   ],
   "source": [
    "assert os.path.exists(csv_path), f\"CSV not found: {csv_path}\"\n",
    "df = pd.read_csv(csv_path).sort_values('time').reset_index(drop=True)\n",
    "print(\"Loaded:\", df.shape)\n",
    "\n",
    "X_all, y1_all, y2_all = make_features_full(\n",
    "    df,\n",
    "    lag_list=lag_list,\n",
    "    roll_windows=roll_windows,\n",
    "    z_windows=z_windows,\n",
    "    ewma_spans=ewma_spans,\n",
    "    rcorr_windows=rcorr_windows,\n",
    "    rcov_windows=rcov_windows,\n",
    "    rcorr_topk=rcorr_topk\n",
    ")\n",
    "print(\"Features shape:\", X_all.shape)\n",
    "\n",
    "times = X_all['time'].values\n",
    "folds = build_folds_by_time(times, n_folds=n_folds, min_train_frac=min_train_frac)\n",
    "print(\"Folds:\", len(folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "380ec5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold 1/4] done\n",
      "[fold 2/4] done\n",
      "[fold 3/4] done\n",
      "[fold 4/4] done\n",
      "\n",
      "[Y1] Equal-weight blend (XGB+Cat):\n",
      "Mean R²: 0.7423919326651036\n",
      "Std  R²: 0.03567672216073825\n",
      "Folds : [0.7722805893392132, 0.7797416230064587, 0.6923033147909978, 0.7252422035237454]\n"
     ]
    }
   ],
   "source": [
    "mdl_y1 = models_y1()\n",
    "if len(mdl_y1) == 0:\n",
    "    raise RuntimeError(\"No Y1 models available (need at least XGBoost or CatBoost).\")\n",
    "\n",
    "res_y1, cache_y1 = run_cv(\n",
    "    X_all, y1_all, mdl_y1, folds,\n",
    "    use_pca=use_pca_y1, pca_components=0  # Y1 PCA off\n",
    ")\n",
    "\n",
    "# Build equal-weight blend if both are present; else use the single available model\n",
    "names = [name for name, _ in mdl_y1]\n",
    "if len(names) >= 2:\n",
    "    blend_scores = []\n",
    "    for i, (_, va_idx) in enumerate(folds):\n",
    "        yhats = []\n",
    "        for name in names:\n",
    "            idxs, pred = cache_y1[name][i]\n",
    "            yhats.append(pred)\n",
    "        y_blend = np.mean(np.vstack(yhats), axis=0)\n",
    "        r2 = r2_score(y1_all.iloc[va_idx], y_blend)\n",
    "        blend_scores.append(r2)\n",
    "    print(\"\\n[Y1] Equal-weight blend (XGB+Cat):\")\n",
    "    print(\"Mean R²:\", float(np.mean(blend_scores)))\n",
    "    print(\"Std  R²:\", float(np.std(blend_scores)))\n",
    "    print(\"Folds :\", [float(x) for x in blend_scores])\n",
    "else:\n",
    "    only = names[0]\n",
    "    print(\"\\n[Y1] Single model (no blend available):\", only)\n",
    "    print(\"Mean R²:\", float(np.mean(res_y1[only])))\n",
    "    print(\"Std  R²:\", float(np.std(res_y1[only])))\n",
    "    print(\"Folds :\", [float(x) for x in res_y1[only]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c634a896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def y2_equal_weight_blend(cache, y, folds, names=(\"XGBoost\",\"CatBoost\")):\n",
    "    if not all(n in cache for n in names):\n",
    "        return None\n",
    "    scores = []\n",
    "    for i, (_, va_idx) in enumerate(folds):\n",
    "        yhats = []\n",
    "        for n in names:\n",
    "            idxs, pred = cache[n][i]\n",
    "            yhats.append(pred)\n",
    "        y_blend = np.mean(np.vstack(yhats), axis=0)\n",
    "        scores.append(r2_score(y.iloc[va_idx], y_blend))\n",
    "    return scores\n",
    "\n",
    "def best_convex_weight_1d(cache, y, folds, names=(\"XGBoost\",\"CatBoost\"), grid_step=0.01):\n",
    "    # Build full OOF vectors\n",
    "    X_xgb, X_cat, y_true = [], [], []\n",
    "    for i, (_, va_idx) in enumerate(folds):\n",
    "        _, px = cache[names[0]][i]\n",
    "        _, pc = cache[names[1]][i]\n",
    "        X_xgb.append(px); X_cat.append(pc); y_true.append(y.iloc[va_idx].values)\n",
    "    X_xgb = np.concatenate(X_xgb)\n",
    "    X_cat = np.concatenate(X_cat)\n",
    "    y_true = np.concatenate(y_true)\n",
    "\n",
    "    best_w, best_r2 = 0.5, -1e9\n",
    "    ws = np.arange(0.0, 1.0 + 1e-9, grid_step)\n",
    "    for w in ws:\n",
    "        y_hat = w * X_xgb + (1 - w) * X_cat\n",
    "        r2 = r2_score(y_true, y_hat)\n",
    "        if r2 > best_r2:\n",
    "            best_w, best_r2 = float(w), float(r2)\n",
    "    return best_w, best_r2\n",
    "\n",
    "def apply_convex_weight_per_fold(cache, y, folds, w, names=(\"XGBoost\",\"CatBoost\")):\n",
    "    scores = []\n",
    "    for i, (_, va_idx) in enumerate(folds):\n",
    "        _, px = cache[names[0]][i]\n",
    "        _, pc = cache[names[1]][i]\n",
    "        y_hat = w * px + (1 - w) * pc\n",
    "        scores.append(r2_score(y.iloc[va_idx], y_hat))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce64dbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl_y2 = models_y2()\n",
    "if len(mdl_y2) == 0:\n",
    "    raise RuntimeError(\"No Y2 models available (need at least XGBoost or CatBoost).\")\n",
    "\n",
    "res_y2, cache_y2 = run_cv(\n",
    "    X_all, y2_all, mdl_y2, folds,\n",
    "    use_pca=use_pca_y2, pca_components=pca_components_y2\n",
    ")\n",
    "\n",
    "names = [name for name, _ in mdl_y2]\n",
    "if set((\"XGBoost\",\"CatBoost\")).issubset(set(names)):\n",
    "    # Show base-model CV first\n",
    "    print(\"\\n[Y2] Base models CV R²:\")\n",
    "    for n in (\"XGBoost\",\"CatBoost\"):\n",
    "        scores = res_y2[n]\n",
    "        print(f\"  {n:8s}: mean={np.mean(scores):.6f}, std={np.std(scores):.6f}, folds={np.round(scores,6)}\")\n",
    "\n",
    "    # Equal-weight blend\n",
    "    eq_scores = y2_equal_weight_blend(cache_y2, y2_all, folds, (\"XGBoost\",\"CatBoost\"))\n",
    "    print(\"\\n[Y2] Equal-weight blend (XGB+Cat):\")\n",
    "    print(\"  mean=\", float(np.mean(eq_scores)), \"std=\", float(np.std(eq_scores)))\n",
    "    print(\"  folds:\", [float(s) for s in eq_scores])\n",
    "\n",
    "    # Convex 1D blend (robust, avoids bad weights)\n",
    "    w, r2_oof = best_convex_weight_1d(cache_y2, y2_all, folds, (\"XGBoost\",\"CatBoost\"), grid_step=0.01)\n",
    "    fold_scores = apply_convex_weight_per_fold(cache_y2, y2_all, folds, w, (\"XGBoost\",\"CatBoost\"))\n",
    "    print(f\"\\n[Y2] Convex blend (XGB weight={w:.2f}, Cat weight={1-w:.2f})\")\n",
    "    print(\"  OOF R² (global):\", r2_oof)\n",
    "    print(\"  CV folds R²     :\", [float(s) for s in fold_scores])\n",
    "    print(\"  mean=\", float(np.mean(fold_scores)), \"std=\", float(np.std(fold_scores)))\n",
    "\n",
    "else:\n",
    "    # Only one model available\n",
    "    only = names[0]\n",
    "    print(\"\\n[Y2] Single model (no blending):\", only)\n",
    "    print(\"  mean=\", float(np.mean(res_y2[only])), \"std=\", float(np.std(res_y2[only])))\n",
    "    print(\"  folds:\", [float(x) for x in res_y2[only]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65101be7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
